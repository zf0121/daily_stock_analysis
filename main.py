# -*- coding: utf-8 -*-
"""
===================================
è‡ªé€‰è‚¡ & åŠ å¯†è´§å¸æ™ºèƒ½åˆ†æç³»ç»Ÿ
===================================
ä¿®æ”¹ç‚¹ï¼š
1. é›†æˆ CryptoFetcherï¼Œæ”¯æŒ BTC/ETH ç­‰è™šæ‹Ÿè´§å¸åˆ†æ
2. è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ä¸åŠ å¯†è´§å¸ä»£ç 
3. æ³¨å…¥é“¾ä¸Šæƒ…ç»ªæ•°æ®ï¼ˆææ…Œè´ªå©ªæŒ‡æ•°ï¼‰
"""
import os

# ä»£ç†é…ç½® - ä»…åœ¨æœ¬åœ°ç¯å¢ƒä½¿ç”¨
if os.getenv("GITHUB_ACTIONS") != "true":
    pass

import argparse
import logging
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, date, timezone, timedelta
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

from config import get_config, Config
from storage import get_db, DatabaseManager
from data_provider import DataFetcherManager
# å¯¼å…¥æ–°å¢çš„ CryptoFetcher
from data_provider.crypto_fetcher import CryptoFetcher
from data_provider.akshare_fetcher import AkshareFetcher, RealtimeQuote, ChipDistribution
from analyzer import GeminiAnalyzer, AnalysisResult, STOCK_NAME_MAP
from notification import NotificationService, NotificationChannel, send_daily_report
from search_service import SearchService, SearchResponse
from enums import ReportType
from stock_analyzer import StockTrendAnalyzer, TrendAnalysisResult
from market_analyzer import MarketAnalyzer

# é…ç½®æ—¥å¿—æ ¼å¼
LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

def setup_logging(debug: bool = False, log_dir: str = "./logs") -> None:
    level = logging.DEBUG if debug else logging.INFO
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    today_str = datetime.now().strftime('%Y%m%d')
    log_file = log_path / f"analysis_{today_str}.log"
    
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(console_handler)
    
    file_handler = RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(file_handler)

logger = logging.getLogger(__name__)

class StockAnalysisPipeline:
    def __init__(self, config: Optional[Config] = None, max_workers: Optional[int] = None):
        self.config = config or get_config()
        self.max_workers = max_workers or self.config.max_workers
        self.db = get_db()
        self.fetcher_manager = DataFetcherManager()
        self.crypto_fetcher = CryptoFetcher()  # åˆå§‹åŒ–åŠ å¯†è´§å¸æŠ“å–å™¨
        self.akshare_fetcher = AkshareFetcher()
        self.trend_analyzer = StockTrendAnalyzer()
        self.analyzer = GeminiAnalyzer()
        self.notifier = NotificationService()
        self.search_service = SearchService(
            bocha_keys=self.config.bocha_api_keys,
            tavily_keys=self.config.tavily_api_keys,
            serpapi_keys=self.config.serpapi_keys,
        )
        logger.info(f"è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æŒè‚¡ç¥¨ä¸åŠ å¯†è´§å¸åŒæ¨¡åˆ†æ")

    def is_crypto(self, code: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŠ å¯†è´§å¸ä»£ç  (åŒ…å«å­—æ¯å³è§†ä¸ºåŠ å¯†è´§å¸)"""
        return any(c.isalpha() for c in code)

    def fetch_and_save_stock_data(self, code: str, force_refresh: bool = False) -> Tuple[bool, Optional[str]]:
        try:
            today = date.today()
            if not force_refresh and self.db.has_today_data(code, today):
                return True, None
            
            if self.is_crypto(code):
                logger.info(f"[{code}] è¯†åˆ«ä¸ºåŠ å¯†è´§å¸ï¼Œä» yfinance è·å–æ•°æ®...")
                df = self.crypto_fetcher.get_crypto_data(code)
                source_name = "yfinance"
            else:
                logger.info(f"[{code}] è¯†åˆ«ä¸ºè‚¡ç¥¨ï¼Œä» AkShare è·å–æ•°æ®...")
                df, source_name = self.fetcher_manager.get_daily_data(code, days=30)
            
            if df is None or df.empty:
                return False, "è·å–æ•°æ®ä¸ºç©º"
            
            saved_count = self.db.save_daily_data(df, code, source_name)
            return True, None
        except Exception as e:
            return False, str(e)

    def analyze_stock(self, code: str) -> Optional[AnalysisResult]:
        try:
            is_crypto_asset = self.is_crypto(code)
            stock_name = STOCK_NAME_MAP.get(code, code)
            extra_context = ""
            
            # --- åŠ å¯†è´§å¸ç‰¹æœ‰é€»è¾‘ ---
            if is_crypto_asset:
                logger.info(f"[{code}] æ­£åœ¨è·å–é“¾ä¸Šæƒ…ç»ªæ•°æ®...")
                extra_context = self.crypto_fetcher.get_onchain_sentiment()
                realtime_quote = None 
                chip_data = None
            else:
                # --- åŸæœ‰è‚¡ç¥¨é€»è¾‘ ---
                realtime_quote = self.akshare_fetcher.get_realtime_quote(code)
                if realtime_quote and realtime_quote.name:
                    stock_name = realtime_quote.name
                chip_data = self.akshare_fetcher.get_chip_distribution(code)

            # è·å–æŠ€æœ¯é¢ä¸Šä¸‹æ–‡
            context = self.db.get_analysis_context(code)
            if not context: return None
            
            # è¶‹åŠ¿åˆ†æ (Crypto åŒæ ·é€‚ç”¨ MA è¶‹åŠ¿)
            import pandas as pd
            df = pd.DataFrame(context.get('raw_data', []))
            trend_result = self.trend_analyzer.analyze(df, code) if not df.empty else None

            # å¢å¼ºä¸Šä¸‹æ–‡
            enhanced_context = self._enhance_context(context, realtime_quote, chip_data, trend_result, stock_name)
            
            # æœç´¢æƒ…æŠ¥ (Crypto ä¹Ÿä¼šæœç´¢æœ€æ–°æ–°é—»)
            news_context = None
            if self.search_service.is_available:
                intel_results = self.search_service.search_comprehensive_intel(code, stock_name, max_searches=2)
                news_context = self.search_service.format_intel_report(intel_results, stock_name)

            # è°ƒç”¨ AI åˆ†æ (ä¼ å…¥ is_crypto æ ‡è®°)
            result = self.analyzer.analyze(
                enhanced_context, 
                news_context=news_context, 
                extra_context=extra_context,
                is_crypto=is_crypto_asset  # æ³¨æ„ï¼šéœ€è¦åœ¨ analyzer.py ä¸­é€‚é…æ­¤å‚æ•°
            )
            return result
        except Exception as e:
            logger.error(f"[{code}] åˆ†æå¼‚å¸¸: {e}")
            return None

    def _enhance_context(self, context, realtime_quote, chip_data, trend_result, stock_name):
        enhanced = context.copy()
        enhanced['stock_name'] = stock_name
        if realtime_quote:
            enhanced['realtime'] = {
                'price': realtime_quote.price,
                'volume_ratio': realtime_quote.volume_ratio,
                'turnover_rate': realtime_quote.turnover_rate
            }
        if chip_data:
            enhanced['chip'] = {'profit_ratio': chip_data.profit_ratio, 'chip_status': chip_data.get_chip_status(realtime_quote.price if realtime_quote else 0)}
        if trend_result:
            enhanced['trend_analysis'] = {
                'trend_status': trend_result.trend_status.value,
                'buy_signal': trend_result.buy_signal.value,
                'signal_score': trend_result.signal_score
            }
        return enhanced

    def process_single_stock(self, code: str, skip_analysis: bool = False, single_stock_notify: bool = False, report_type: ReportType = ReportType.SIMPLE) -> Optional[AnalysisResult]:
        logger.info(f"========== å¼€å§‹å¤„ç† {code} ==========")
        success, error = self.fetch_and_save_stock_data(code)
        if skip_analysis: return None
        result = self.analyze_stock(code)
        if result and single_stock_notify and self.notifier.is_available():
            report_content = self.notifier.generate_single_stock_report(result)
            self.notifier.send(report_content)
        return result

    def run(self, stock_codes: Optional[List[str]] = None, dry_run: bool = False, send_notification: bool = True) -> List[AnalysisResult]:
        start_time = time.time()
        if stock_codes is None:
            self.config.refresh_stock_list()
            stock_codes = self.config.stock_list
        if not stock_codes: return []
        
        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ŒåŒ…å« {len(stock_codes)} ä¸ªæ ‡çš„")
        single_stock_notify = getattr(self.config, 'single_stock_notify', False)
        
        results = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_code = {executor.submit(self.process_single_stock, code, dry_run, single_stock_notify and send_notification): code for code in stock_codes}
            for future in as_completed(future_to_code):
                try:
                    res = future.result()
                    if res: results.append(res)
                except Exception as e:
                    logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        
        if results and send_notification and not dry_run:
            if not single_stock_notify:
                self._send_notifications(results)
        return results

    def _send_notifications(self, results: List[AnalysisResult]):
        try:
            report = self.notifier.generate_dashboard_report(results)
            self.notifier.save_report_to_file(report)
            if self.notifier.is_available():
                self.notifier.send(report)
        except Exception as e:
            logger.error(f"é€šçŸ¥å‘é€å¤±è´¥: {e}")

def run_full_analysis(config: Config, args: argparse.Namespace, stock_codes: Optional[List[str]] = None):
    try:
        pipeline = StockAnalysisPipeline(config=config, max_workers=args.workers)
        results = pipeline.run(stock_codes=stock_codes, dry_run=args.dry_run, send_notification=not args.no_notify)
        
        # å¤§ç›˜å¤ç›˜é€»è¾‘ (ä¿æŒåŸæ ·)
        market_report = ""
        if config.market_review_enabled and not args.no_market_review:
            market_report = run_market_review(pipeline.notifier, pipeline.analyzer, pipeline.search_service)

        # é£ä¹¦æ–‡æ¡£ç”Ÿæˆ (ä¿æŒåŸæ ·)
        try:
            feishu_doc = FeishuDocManager()
            if feishu_doc.is_configured() and (results or market_report):
                doc_title = f"{datetime.now().strftime('%Y-%m-%d %H:%M')} æŠ•èµ„å¤ç›˜"
                full_content = ""
                if market_report: full_content += f"# ğŸ“ˆ å¤§ç›˜å¤ç›˜\n\n{market_report}\n\n---\n\n"
                if results: full_content += f"# ğŸš€ å†³ç­–ä»ªè¡¨ç›˜\n\n{pipeline.notifier.generate_dashboard_report(results)}"
                feishu_doc.create_daily_doc(doc_title, full_content)
        except Exception as e:
            logger.error(f"é£ä¹¦ç”Ÿæˆå¤±è´¥: {e}")
    except Exception as e:
        logger.exception(f"æ‰§è¡Œå¤±è´¥: {e}")

def run_market_review(notifier, analyzer, search_service):
    try:
        market_analyzer = MarketAnalyzer(search_service=search_service, analyzer=analyzer)
        review_report = market_analyzer.run_daily_review()
        if review_report:
            notifier.send(f"ğŸ¯ å¤§ç›˜å¤ç›˜\n\n{review_report}")
            return review_report
    except Exception as e:
        logger.error(f"å¤§ç›˜å¤ç›˜å¤±è´¥: {e}")
    return None

def parse_arguments():
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨ & åŠ å¯†è´§å¸æ™ºèƒ½åˆ†æç³»ç»Ÿ')
    parser.add_argument('--debug', action='store_true')
    parser.add_argument('--dry-run', action='store_true')
    parser.add_argument('--stocks', type=str)
    parser.add_argument('--no-notify', action='store_true')
    parser.add_argument('--workers', type=int, default=3)
    parser.add_argument('--schedule', action='store_true')
    parser.add_argument('--market-review', action='store_true')
    parser.add_argument('--no-market-review', action='store_true')
    return parser.parse_args()

def main():
    args = parse_arguments()
    config = get_config()
    setup_logging(debug=args.debug, log_dir=config.log_dir)
    
    stock_codes = [c.strip() for c in args.stocks.split(',')] if args.stocks else None
    
    if args.schedule or config.schedule_enabled:
        from scheduler import run_with_schedule
        run_with_schedule(task=lambda: run_full_analysis(config, args, stock_codes), schedule_time=config.schedule_time, run_immediately=True)
    else:
        run_full_analysis(config, args, stock_codes)
    return 0

if __name__ == "__main__":
    sys.exit(main())
